{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611567dbec5f4dc6",
   "metadata": {},
   "source": [
    "# Alzheimer textual explanation, visual explanation and classification\n",
    "In this notebook there's all the procedure we do for the classification and for the explanation.\n",
    "\n",
    "For the realization of this project i start from the code of my colleague.\n",
    "\n",
    "In this notebook we suppose that you have already the dataset and the explanation, if else, \n",
    "you will run \"Creation of the dataset\" before this notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "919f80c27494ade4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:39.926918Z",
     "start_time": "2024-07-01T13:31:02.238009Z"
    }
   },
   "source": [
    "import os, random, glob, cv2\n",
    "import nltk\n",
    " \n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sys import platform\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import importlib\n",
    "import Utility\n",
    "importlib.reload(Utility)\n",
    "from Utility import get_gradcam, get_transformations_transformer\n",
    "from alzheimer_disease.src.helpers.utils import get_device\n",
    "from alzheimer_disease.src.modules.training import training_model\n",
    "from alzheimer_disease.src.helpers.config import get_config\n",
    "from alzheimer_disease.src.modules.preprocessing import get_transformations\n",
    "from alzheimer_disease.src.models.densenetmm import DenseNetMM\n",
    "\n",
    "#nltk.download('punkt')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "63f4224939e588e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:40.043234Z",
     "start_time": "2024-07-01T13:34:39.931794Z"
    }
   },
   "source": [
    "# Definition of all paths\n",
    "dataset = 'oasis_aug'\n",
    "\n",
    "_base_path = '/Volumes/Seagate Bas/Vito/CV'\n",
    "_config = get_config()\n",
    "saved_path = os.path.join(_base_path, _config.get('SAVED_FOLDER'))\n",
    "reports_path = os.path.join(_base_path, _config.get('REPORT_FOLDER'))\n",
    "logs_path = os.path.join(_base_path, _config.get('LOG_FOLDER'))\n",
    "_data_path = os.path.join(_base_path, _config.get('LOCAL_DATA'))\n",
    "data_path, meta_path, explanation_path = [\n",
    "    os.path.join(_data_path, dataset, 'data/'),\n",
    "    os.path.join(_data_path, dataset, 'meta/'),\n",
    "    os.path.join(_data_path, dataset, 'explainability/')\n",
    "]\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "if platform == 'win32':\n",
    "    saved_path = saved_path.replace('/', '\\\\')\n",
    "    reports_path = reports_path.replace('/', '\\\\')\n",
    "    logs_path = logs_path.replace('/', '\\\\')\n",
    "    data_path = data_path.replace('/', '\\\\')\n",
    "    meta_path = meta_path.replace('/', '\\\\')\n",
    "    explanation_path = explanation_path.replace('/', '\\\\')\n",
    "\n",
    "saved_path, reports_path, logs_path, data_path, meta_path, explanation_path, device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Volumes/Seagate Bas/Vito/CV/saved/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/reports/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/logs/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/data/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/meta/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/explainability/',\n",
       " 'cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "1abdcaaf50e4b278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:40.046694Z",
     "start_time": "2024-07-01T13:34:40.044388Z"
    }
   },
   "source": [
    "SIZE = 128\n",
    "output_length = 1024\n",
    "epochs = 30\n",
    "name_model = 'DenseNetMM_best'\n",
    "\n",
    "CHANNELS = ['T2w']\n",
    "\n",
    "FEATURES = ['sex', 'age', 'bmi', 'education', 'cdr_memory', 'cdr_orientation', 'cdr_judgment', 'cdr_community', 'cdr_hobbies', 'cdr_personalcare', 'boston_naming_test', 'depression', 'sleeping_disorder', 'motor_disturbance']\n",
    "MULTICLASS = True"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7c21fb3c080ba3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:40.060628Z",
     "start_time": "2024-07-01T13:34:40.048305Z"
    }
   },
   "source": [
    "# I started with the train test split of colleague and adapt to my task\n",
    "def train_test_splitting(\n",
    "        data_folder,\n",
    "        meta_folder,\n",
    "        explanation_folder,\n",
    "        channels,\n",
    "        features,\n",
    "        train_ratio=.8,\n",
    "        multiclass=False,\n",
    "        verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Splitting train/eval/test.\n",
    "    Args:\n",
    "        data_folder (str): path of the folder containing images.\n",
    "        meta_folder (str): path of the folder containing csv files.\n",
    "        explanation_folder (str): path of the folder containing csv files of the explanation.\n",
    "        channels (list): image channels to select (values `T1w`, `T2w` or both).\n",
    "        features (list): features set to select.\n",
    "        train_ratio (float): ratio of the training set, value between 0 and 1.\n",
    "        multiclass (bool): `False` for binary classification, `True` for ternary classification.\n",
    "        verbose (bool): whether or not print information.\n",
    "    Returns:\n",
    "        train_data (list): the training data ready to feed monai.data.Dataset\n",
    "        eval_data (list): the evaluation data ready to feed monai.data.Dataset\n",
    "        test_data (list): the testing data ready to feed monai.data.Dataset.\n",
    "        (see https://docs.monai.io/en/latest/data.html#monai.data.Dataset).\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.read_csv(os.path.join(meta_folder, 'data_num.csv'))\n",
    "    df1 = df[(df['weight'] != .0) & (df['height'] != .0)]\n",
    "    df['bmi'] = round(df1['weight'] / (df1['height'] * df1['height']), 0)\n",
    "    df['bmi'] = df['bmi'].fillna(.0)\n",
    "    sessions = [s.split('_')[0] for s in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, s))]\n",
    "    subjects = list(set(sessions))\n",
    "\n",
    "    # uploading of the dataset\n",
    "    explanation = pd.read_csv(explanation_folder + 'explaination.csv', sep=';')\n",
    "\n",
    "\n",
    "\n",
    "    # applying splitting on subjects to prevent data leakage\n",
    "    random.shuffle(subjects)\n",
    "    split_train = int(len(subjects) * train_ratio)\n",
    "    train_subjects, test_subjects = subjects[:split_train], subjects[split_train:]\n",
    "    split_eval = int(len(train_subjects) * .8)\n",
    "    eval_subjects = train_subjects[split_eval:]\n",
    "    train_subjects = train_subjects[:split_eval]\n",
    "\n",
    "    # applying multiclass label correction and splitting\n",
    "    if multiclass:\n",
    "        train_subjects, eval_subjects, test_subjects = [], [], []\n",
    "        df.loc[df['cdr'] == .0, 'final_dx'] = .0\n",
    "        df.loc[df['cdr'] == .5, 'final_dx'] = 1.\n",
    "        df.loc[(df['cdr'] != .0) & (df['cdr'] != .5), 'final_dx'] = 2.\n",
    "        m = np.min(np.unique(df['final_dx'].to_numpy(), return_counts=True)[1])\n",
    "        df = pd.concat([\n",
    "            df[df['final_dx'] == .0].sample(m),\n",
    "            df[df['final_dx'] == 1.].sample(m),\n",
    "            df[df['final_dx'] == 2.].sample(m)\n",
    "        ], ignore_index=True)\n",
    "        n_test = m - int(m * train_ratio)\n",
    "        n_eval = m - n_test - int(m * train_ratio * train_ratio)\n",
    "        for i in range(3):\n",
    "            sub = list(set(df[df['final_dx'] == float(i)]['subject_id'].to_numpy()))\n",
    "            random.shuffle(sub)\n",
    "            counter = 0\n",
    "            for j in range(len(sub)):\n",
    "                counter += len(df[df['subject_id'] == sub[j]])\n",
    "                if counter <= n_test:\n",
    "                    test_subjects.append(sub[j])\n",
    "                elif counter > n_test and counter <= (n_test + n_eval):\n",
    "                    eval_subjects.append(sub[j])\n",
    "                else:\n",
    "                    train_subjects.append(sub[j])\n",
    "\n",
    "    # loading sessions paths\n",
    "    X_train = df[df['subject_id'].isin(train_subjects)]\n",
    "    X_eval = df[df['subject_id'].isin(eval_subjects)]\n",
    "    X_test = df[df['subject_id'].isin(test_subjects)]\n",
    "    train_sessions = [os.path.join(data_folder, s) for s in X_train['session_id'].values]\n",
    "    eval_sessions = [os.path.join(data_folder, s) for s in X_eval['session_id'].values]\n",
    "    test_sessions = [os.path.join(data_folder, s) for s in X_test['session_id'].values]\n",
    "\n",
    "    # loading explanation of subjects\n",
    "    explanation_train = explanation[explanation['subject_id'].isin(X_train['subject_id'].values)]\n",
    "    explanation_eval = explanation[explanation['subject_id'].isin(X_eval['subject_id'].values)]\n",
    "    explanation_test = explanation[explanation['subject_id'].isin(X_test['subject_id'].values)]\n",
    "\n",
    "    # scaling numerical data in range [0,1]\n",
    "    X_train.loc[:, features] = scaler.fit_transform(X_train[features])\n",
    "    X_eval.loc[:, features] = scaler.fit_transform(X_eval[features])\n",
    "    X_test.loc[:, features] = scaler.fit_transform(X_test[features])\n",
    "\n",
    "    # arranging data in dictionaries\n",
    "    # I will also take the reference session of the explanation and the image\n",
    "    train_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_train[X_train['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_train[explanation_train['session_id'] == s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in train_sessions]\n",
    "    eval_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_eval[X_eval['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_eval[explanation_eval['session_id']==s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in eval_sessions]\n",
    "    test_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_test[X_test['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_test[explanation_test['session_id'] == s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in test_sessions]\n",
    "\n",
    "    # print data splitting information\n",
    "    if verbose:\n",
    "        print(''.join(['> ' for _ in range(40)]))\n",
    "        print(f'\\n{\"\":<20}{\"TRAINING\":<20}{\"EVALUATION\":<20}{\"TESTING\":<20}\\n')\n",
    "        print(''.join(['> ' for _ in range(40)]))\n",
    "        tsb1 = str(len(train_subjects)) + ' (' + str(round((len(train_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tsb2 = str(len(eval_subjects)) + ' (' + str(round((len(eval_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tsb3 = str(len(test_subjects)) + ' (' + str(round((len(test_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tss1 = str(len(train_sessions)) + ' (' + str(round((len(train_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        tss2 = str(len(eval_sessions)) + ' (' + str(round((len(eval_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        tss3 = str(len(test_sessions)) + ' (' + str(round((len(test_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        print(f'\\n{\"subjects\":<20}{tsb1:<20}{tsb2:<20}{tsb3:<20}\\n')\n",
    "        print(f'{\"sessions\":<20}{tss1:<20}{tss2:<20}{tss3:<20}\\n')\n",
    "\n",
    "    return train_data, eval_data, test_data"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "72b25c026b7fb31b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:40.261735Z",
     "start_time": "2024-07-01T13:34:40.061217Z"
    }
   },
   "source": [
    "densenet = DenseNetMM(\n",
    "    in_channels = len(CHANNELS),\n",
    "    in_size = SIZE,\n",
    "    in_features_size= len(FEATURES),\n",
    "    out_channels = 3 if MULTICLASS else 2,\n",
    "    append_features = True,\n",
    "    name=name_model\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "6b704a8642ecf907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:41.935677Z",
     "start_time": "2024-07-01T13:34:40.262461Z"
    }
   },
   "source": [
    "train_transform, eval_transform = get_transformations(size=SIZE)\n",
    "\n",
    "train, val, test = train_test_splitting(\n",
    "    data_folder=data_path,\n",
    "    meta_folder=meta_path,\n",
    "    explanation_folder=explanation_path,\n",
    "    channels=CHANNELS,\n",
    "    features=FEATURES,\n",
    "    multiclass=MULTICLASS,\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
      "\n",
      "                    TRAINING            EVALUATION          TESTING             \n",
      "\n",
      "> > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
      "\n",
      "subjects            373 (63.0 %)        101 (17.0 %)        117 (20.0 %)        \n",
      "\n",
      "sessions            435 (63.6 %)        111 (16.23 %)       138 (20.18 %)       \n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a143df277ef4f5dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:41.939172Z",
     "start_time": "2024-07-01T13:34:41.936358Z"
    }
   },
   "source": [
    "train[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': ['/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/data/OAS31232_MR_d0159/sub-OAS31232_sess-d0159_T2w.nii.gz'],\n",
       " 'data': array([1.        , 0.28      , 0.60869565, 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.5       , 0.5       , 0.5       ]),\n",
       " 'label': 0.0,\n",
       " 'explanation': \"**Summary of Heatmap Analysis**\\n\\nThe heatmap analysis reveals that the classifier model focused on several regions in the brain, which are not areas typically affected by Alzheimer's Disease. The regions highlighted by the heatmap are:\\n\\n1. **Frontal-to-Occipital (GapMap) left**: This region accounts for 19.9% of the heatmap and 17.81% of the region affected. The GapMap is a network of brain regions involved in attention, working memory, and spatial processing. The model's focus on this region may indicate that it is searching for patterns related to cognitive decline or changes in brain function that are not directly related to Alzheimer's Disease pathology. Clinically, this could encourage further investigation into the relationship between cognitive decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\n2. **Area hOc1 (V1, 17, CalcS) left**: This region accounts for 13.24% of the heatmap and 43.39% of the region affected. Area hOc1 is a region involved in visual processing, particularly in the processing of complex shapes and patterns. The model's focus on this region may indicate that it is searching for patterns related to visual processing or visual decline, which could be an important aspect of Alzheimer's Disease diagnosis. Clinically, this could encourage further investigation into the relationship between visual decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\n3. **Temporal-to-Parietal (GapMap) left**: This region accounts for 12.87% of the heatmap and 7.68% of the region affected. The Temporal-to-Parietal GapMap is a network of brain regions involved in attention, working memory, and spatial processing. The model's focus on this region may indicate that it is searching for patterns related to cognitive decline or changes in brain function that are not directly related to Alzheimer's Disease pathology. Clinically, this could encourage further investigation into the relationship between cognitive decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\n4. **Area hOc4v (LingG) left**: This region accounts for 8.06% of the heatmap and 68.77% of the region affected. Area hOc4v is a region involved in language processing, particularly in the processing of semantic meaning. The model's focus on this region may indicate that it is searching for patterns related to language decline or changes in brain function that are not directly related to Alzheimer's Disease pathology. Clinically, this could encourage further investigation into the relationship between language decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\n5. **Area hOc3v (LingG) left**: This region accounts for 6.54% of the heatmap and 51.49% of the region affected. Area hOc3v is a region involved in language processing, particularly in the processing of phonological information. The model's focus on this region may indicate that it is searching for patterns related to language decline or changes in brain function that are not directly related to Alzheimer's Disease pathology. Clinically, this could encourage further investigation into the relationship between language decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\n**Conclusion**\\n\\nThe heatmap analysis reveals that the classifier model focused on regions that are not typically affected by Alzheimer's Disease, but are involved in various cognitive and neural processes. The model's focus on these regions may indicate that it is searching for patterns related to cognitive decline or changes in brain function that are not directly related to Alzheimer's Disease pathology. Clinically, this could encourage further investigation into the relationship between cognitive decline and Alzheimer's Disease, particularly in the context of early diagnosis and prevention.\\n\\nThe insights gained from the heatmap analysis could enhance clinical decision-making by highlighting potential areas of investigation and encouraging a more nuanced understanding of Alzheimer's Disease pathology and diagnosis.\",\n",
       " 'session_id': 'OAS31232_MR_d0159'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c7d109ec7057aa1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:43.701735Z",
     "start_time": "2024-07-01T13:34:41.939818Z"
    }
   },
   "source": [
    "if glob.glob(saved_path+ f'{name_model}.pth'):\n",
    "\tprint(f'Loading {name_model}.pth')\n",
    "\tdensenet.load_state_dict(torch.load(saved_path + f'{name_model}.pth'))\n",
    "else:\n",
    "\tprint('Train of the model')\n",
    "\ttrain_metrics = training_model(\n",
    "\t\tmodel = densenet,\n",
    "\t\tdata = [train, val],\n",
    "\t\ttransforms = [train_transform, eval_transform],\n",
    "\t\tepochs = epochs,\n",
    "\t\tdevice = get_device(),\n",
    "\t\tpaths = [saved_path, reports_path, logs_path],\n",
    "\t\tnum_workers=0,\n",
    "\t\tverbose=True\n",
    "\t)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DenseNetMM_best.pth\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "151e3073d8cfb812",
   "metadata": {},
   "source": [
    "## Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "id": "36632317f8234359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:43.704165Z",
     "start_time": "2024-07-01T13:34:43.702528Z"
    }
   },
   "source": [
    "name_fextractor = 'DenseNetMMFeatureExtractor'"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "abeaaea064344a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:43.977898Z",
     "start_time": "2024-07-01T13:34:43.706495Z"
    }
   },
   "source": [
    "VOCABULARY_SIZE = 1179\n",
    "#dimensions of the word embedding vector\n",
    "EMBEDDING_DIM = 512\n",
    "# number of units in the recurrent layers\n",
    "UNITS = 512\n",
    "#number of samples that will propagated through the network at once. \n",
    "BATCH_SIZE = 32\n",
    "#shuffling the dataset\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "def preprocess(text):\n",
    "    #conver all text into lower\n",
    "    text = text.lower()\n",
    "    #remove all character from text that are not words and whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    #replace multiple whitespace with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    #remove any leading or trailing whitespace from the text\n",
    "    text = text.strip()\n",
    "    #Add start and end token to the text at begining and end of the text respectively\n",
    "    text = '[start] ' + text + ' [end]'\n",
    "    return text\n",
    "\n",
    "# concat for get all df\n",
    "entire_df = train + val + test\n",
    "\n",
    "all_text = [preprocess(explanation['explanation']) for explanation in entire_df]\n",
    "\n",
    "# tokenize the text\n",
    "#Keras preprocessing layer that transforms text into sequences of integers.\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    #set maximum number of tokens (words) that the tokenizer will keep\n",
    "    max_tokens=VOCABULARY_SIZE, \n",
    "    standardize=None,\n",
    "    #specifies the length of the output sequences\n",
    "    output_sequence_length=output_length\n",
    ")\n",
    "\n",
    "# Adapting the Tokenizer to all caption\n",
    "tokenizer.adapt(all_text)\n",
    "\n",
    "vocab_size = tokenizer.vocabulary_size()\n",
    "print('Vocabulary Size: {}'.format(vocab_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1179\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:43.991476Z",
     "start_time": "2024-07-01T13:34:43.978508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#layer that maps strings to integer indices.\n",
    "word2idx = tf.keras.layers.StringLookup(\n",
    "    #specifies a token that will be treated as a mask\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary())\n",
    "#The vocabulary is obtained from the tokenizer using the get_vocabulary() method, which returns a list of strings\n",
    "#representing the vocabulary in order of frequency (most frequent first).\n",
    "\n",
    "idx2word = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary(),\n",
    "    invert=True\n",
    ")"
   ],
   "id": "c368d06c1d6bcf52",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a73cbe58bf77e466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.202405Z",
     "start_time": "2024-07-01T13:34:43.992125Z"
    }
   },
   "source": [
    "# CNN encoder\n",
    "encoder = DenseNetMM(\n",
    "    in_channels = len(CHANNELS),\n",
    "    in_size = SIZE,\n",
    "    in_features_size= len(FEATURES),\n",
    "    out_channels = 3 if MULTICLASS else 2,\n",
    "    append_features = True,\n",
    "    name=name_fextractor\n",
    ")\n",
    "\n",
    "# Upload the previous model for the feature extraction\n",
    "if glob.glob(saved_path+ f'{name_model}.pth'):\n",
    "\tprint(f'Loading {name_model}.pth')\n",
    "\tencoder.load_state_dict(torch.load(saved_path + f'{name_model}.pth'))\n",
    "else:\n",
    "\tprint('Train of the model')\n",
    "\ttrain_metrics = training_model(\n",
    "\t\tmodel = encoder,\n",
    "\t\tdata = [train, val],\n",
    "\t\ttransforms = [train_transform, eval_transform],\n",
    "\t\tepochs = epochs,\n",
    "\t\tdevice = get_device(),\n",
    "\t\tpaths = [saved_path, reports_path, logs_path],\n",
    "\t\tnum_workers=0,\n",
    "\t\tverbose=True\n",
    "\t)\n",
    "    \n",
    "# get just the feature extractor from image\n",
    "encoder = torch.nn.Sequential(\n",
    "    encoder.features_img,\n",
    "    encoder.output_layers,\n",
    ")\n",
    "\n",
    "encoder"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DenseNetMM_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (conv0): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (norm0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(96, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm3d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (pool): AdaptiveAvgPool3d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.206934Z",
     "start_time": "2024-07-01T13:34:44.203779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embed_dim, activation=\"relu\")\n",
    "\n",
    "    #Forward Pass (call method):\n",
    "    def call(self, x, training):\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        attn_output = self.attention(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            attention_mask=None,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        x = self.layer_norm_2(x + attn_output)\n",
    "\n",
    "        return x"
   ],
   "id": "552152b77df58ef",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.215284Z",
     "start_time": "2024-07-01T13:34:44.209209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embeddings(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, max_len):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim\n",
    "        )\n",
    "        \n",
    "        self.position_embeddings = tf.keras.layers.Embedding(\n",
    "            max_len, embed_dim, input_shape=(None, max_len)\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, input_ids):\n",
    "        #input_ids: A tensor of token IDs representing the input sequences.\n",
    "        length = tf.shape(input_ids)[-1]\n",
    "        #A range of position IDs from 0 to length - 1 is created\n",
    "        position_ids = tf.range(start=0, limit=length, delta=1)\n",
    "        #adds a new axis to make position_ids a batch-compatible tensor of shape\n",
    "        position_ids = tf.expand_dims(position_ids, axis=0)\n",
    "\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "\n",
    "        return token_embeddings + position_embeddings"
   ],
   "id": "3b12e0063048415a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.228463Z",
     "start_time": "2024-07-01T13:34:44.216071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerDecoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, units, num_heads):\n",
    "        super().__init__()\n",
    "# embedding layer to create token and positional embeddings.\n",
    "        self.embedding = Embeddings(\n",
    "            tokenizer.vocabulary_size(), embed_dim, output_length)\n",
    "# for self attention\n",
    "        self.attention_1 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "#for attending to the encoder's output\n",
    "        self.attention_2 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        #three layer normalization layers\n",
    "\n",
    "        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
    "        self.layernorm_3 = tf.keras.layers.LayerNormalization()\n",
    "        #Dense layers for FF network and output layer\n",
    "        self.ffn_layer_1 = tf.keras.layers.Dense(units, activation=\"relu\")\n",
    "        self.ffn_layer_2 = tf.keras.layers.Dense(embed_dim)\n",
    "\n",
    "        self.out = tf.keras.layers.Dense(tokenizer.vocabulary_size(), activation=\"softmax\")\n",
    "        #two dropout layers\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def call(self, input_ids, encoder_output, training, mask=None):\n",
    "        embeddings = self.embedding(input_ids)\n",
    "\n",
    "        combined_mask = None\n",
    "        padding_mask = None\n",
    "        #Prepares the masks for attention mechanisms\n",
    "        if mask is not None:\n",
    "            causal_mask = self.get_causal_attention_mask(embeddings)\n",
    "            padding_mask = tf.cast(mask[:, :, tf.newaxis], dtype=tf.int32)\n",
    "            combined_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)\n",
    "            combined_mask = tf.minimum(combined_mask, causal_mask)\n",
    "        #Applies self-attention on the embeddings\n",
    "        attn_output_1 = self.attention_1(\n",
    "            query=embeddings,\n",
    "            value=embeddings,\n",
    "            key=embeddings,\n",
    "            attention_mask=combined_mask,\n",
    "            training=training\n",
    "        )\n",
    "        #Adds the input embeddings to the attention output and normalizes\n",
    "        out_1 = self.layernorm_1(embeddings + attn_output_1)\n",
    "        #Applies attention on the encoder output (cross-attention).\n",
    "        attn_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_output,\n",
    "            key=encoder_output,\n",
    "            attention_mask=padding_mask,\n",
    "            training=training\n",
    "        )\n",
    "        #Adds the previous output to the cross-attention output and normalizes\n",
    "\n",
    "        out_2 = self.layernorm_2(out_1 + attn_output_2)\n",
    "        #Feedforward network and dropout\n",
    "        ffn_out = self.ffn_layer_1(out_2)\n",
    "        ffn_out = self.dropout_1(ffn_out, training=training)\n",
    "        ffn_out = self.ffn_layer_2(ffn_out)\n",
    "\n",
    "        ffn_out = self.layernorm_3(ffn_out + out_2)\n",
    "        ffn_out = self.dropout_2(ffn_out, training=training)\n",
    "        preds = self.out(ffn_out)\n",
    "        return preds\n",
    "\n",
    "#creates a causal mask to ensure that each position can only attend to earlier positions and itself, preventing information leakage from future tokens\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "\n",
    "class ImageCaptioningModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, cnn_model, encoder, decoder, image_aug=None):\n",
    "        super().__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.image_aug = image_aug\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.acc_tracker = tf.keras.metrics.Mean(name=\"accuracy\")\n",
    "\n",
    "    \n",
    "    #Loss Calculation\n",
    "    def calculate_loss(self, y_true, y_pred, mask):\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    \n",
    "    #This method calculates the masked loss by applying the mask to the loss values\n",
    "    #and then computing the average loss per non-padding token\n",
    "    def calculate_accuracy(self, y_true, y_pred, mask):\n",
    "        accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n",
    "        accuracy = tf.math.logical_and(mask, accuracy)\n",
    "        accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
    "        \n",
    "        \n",
    "    #This method calculates the masked accuracy by comparing predicted tokens to \n",
    "    # #the ground truth tokens and applying the mask\n",
    "    def compute_loss_and_acc(self, img_embed, captions, training=True):\n",
    "        encoder_output = self.encoder(img_embed, training=True)\n",
    "        y_input = captions[:, :-1]\n",
    "        y_true = captions[:, 1:]\n",
    "        mask = (y_true != 0)\n",
    "        y_pred = self.decoder(\n",
    "            y_input, encoder_output, training=True, mask=mask\n",
    "        )\n",
    "        loss = self.calculate_loss(y_true, y_pred, mask)\n",
    "        acc = self.calculate_accuracy(y_true, y_pred, mask)\n",
    "        return loss, acc\n",
    "        \n",
    "        #This method computes the loss and accuracy for a given batch by first encoding\n",
    "        # #the image embeddings, preparing the input and target sequences for the decoder, \n",
    "        # and then calculating the loss and accuracy using the decoder's predictions.\n",
    "    def train_step(self, batch):\n",
    "        imgs, captions = batch\n",
    "\n",
    "        if self.image_aug:\n",
    "            imgs = self.image_aug(imgs)\n",
    "\n",
    "        img_embed = self.cnn_model(imgs)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, acc = self.compute_loss_and_acc(\n",
    "                img_embed, captions\n",
    "            )\n",
    "\n",
    "        train_vars = (\n",
    "            self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "        )\n",
    "        grads = tape.gradient(loss, train_vars)\n",
    "        self.optimizer.apply_gradients(zip(grads, train_vars))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.acc_tracker.update_state(acc)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n",
    "#This method performs a training step, including optional image augmentation, \n",
    "#forward pass, loss and accuracy computation, gradient computation, and model\n",
    " # weights update using the optimizer\n",
    "\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        imgs, captions = batch\n",
    "\n",
    "        img_embed = self.cnn_model(imgs)\n",
    "\n",
    "        loss, acc = self.compute_loss_and_acc(\n",
    "            img_embed, captions, training=False\n",
    "        )\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.acc_tracker.update_state(acc)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n",
    "#This method performs an evaluation step, similar to the training step but\n",
    "#without gradient computation and weight updates.\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.acc_tracker]"
   ],
   "id": "cb7ac120a2781dc5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.235315Z",
     "start_time": "2024-07-01T13:34:44.230181Z"
    }
   },
   "cell_type": "code",
   "source": "train_transform = get_transformations_transformer(size=SIZE)",
   "id": "7c98730bf6265be2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.258592Z",
     "start_time": "2024-07-01T13:34:44.236356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#layer that maps strings to integer indices.\n",
    "word2idx = tf.keras.layers.StringLookup(\n",
    "    #specifies a token that will be treated as a mask\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary())\n",
    "#The vocabulary is obtained from the tokenizer using the get_vocabulary() method, which returns a list of strings\n",
    "#representing the vocabulary in order of frequency (most frequent first).\n",
    "\n",
    "idx2word = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary(),\n",
    "    invert=True)\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, data, transforms=None, tokenizer=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        report = preprocess(self.data[idx]['explanation'])\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        report = self.tokenizer(report)\n",
    "        return {\n",
    "            'img': torch.Tensor(image['image']),\n",
    "            'report': torch.tensor(report.numpy())\n",
    "        }\n",
    "    \n",
    "\n",
    "train_dataset = MedicalDataset(train, train_transform, tokenizer)\n",
    "val_dataset = MedicalDataset(val, train_transform, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset)"
   ],
   "id": "843463564b67b28d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.265170Z",
     "start_time": "2024-07-01T13:34:44.260782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "\n",
    "#initializes a defaultdict with lists as the default value type\n",
    "train_collections = collections.defaultdict(list)\n",
    "# loop iterates over each image-caption pair in the captions DataFrame\n",
    "for img in train:\n",
    "    train_collections[img['image'][0]].append(img['explanation'])\n",
    "#Shuffling and Splitting Keys:\n",
    "\n",
    "img_keys = list(train_collections.keys())\n",
    "random.shuffle(img_keys)\n",
    "val_collection = collections.defaultdict(list)\n",
    "# loop iterates over each image-caption pair in the captions DataFrame\n",
    "for img in val:\n",
    "    val_collection[img['image'][0]].append(img['explanation'])\n",
    "\n",
    "#Creating Training and Validation Data:\n",
    "train_imgs = []\n",
    "train_captions = []\n",
    "for imgt in train_collections:\n",
    "    capt_len = len(train_collections[imgt])\n",
    "    train_imgs.extend([imgt] * capt_len)\n",
    "    train_captions.extend(train_collections[imgt])\n",
    "\n",
    "val_imgs = []\n",
    "val_captions = []\n",
    "for imgv in val_collection:\n",
    "    capv_len = len(val_collection[imgv])\n",
    "    val_imgs.extend([imgv] * capv_len)\n",
    "    val_captions.extend(val_collection[imgv])"
   ],
   "id": "88f1b2e1cb3c404f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:34:44.348774Z",
     "start_time": "2024-07-01T13:34:44.266130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(img_path, caption):\n",
    "    img_path = img_path.decode(\"utf-8\")\n",
    "    # Applica le trasformazioni di MONAI\n",
    "    data_dict = {\"image\": img_path, \"caption\": caption}\n",
    "    data_dict = train_transform(data_dict)\n",
    "    #tokenizes the caption using the tokenizer created earlier\n",
    "    caption = tokenizer(data_dict['caption'])\n",
    "    return data_dict['image'], caption\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_imgs, train_captions))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "        lambda img_path, caption: tf.numpy_function(load_data, [img_path, caption], [tf.float32, tf.string]),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_imgs, val_captions))\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda img_path, caption: tf.numpy_function(load_data, [img_path, caption], [tf.float32, tf.string]),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "id": "387e83e80501ba0d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-01T13:34:44.349665Z"
    }
   },
   "cell_type": "code",
   "source": "Embeddings(tokenizer.vocabulary_size(), EMBEDDING_DIM, output_length)(next(iter(train_dataset))[1]).shape",
   "id": "ac7c2ab504ca7e5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitolosavio/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "encoder_transformer = TransformerEncoderLayer(EMBEDDING_DIM, 1)\n",
    "decoder = TransformerDecoderLayer(EMBEDDING_DIM, UNITS, 8)\n",
    "\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=encoder, encoder=encoder_transformer, decoder=decoder\n",
    ")"
   ],
   "id": "5da583de2af53df8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction=\"none\"\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "caption_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=cross_entropy\n",
    ")"
   ],
   "id": "f24777705b511b5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if not glob.glob(saved_path + 'transformer_caption_model.h5'):\n",
    "    print('Caption model training...')\n",
    "    history = caption_model.fit(\n",
    "        train_loader,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_loader,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    caption_model.save_weights(saved_path + 'transformer_caption_model.h5')\n",
    "else:\n",
    "    print('Loading Caption Model...')\n",
    "    caption_model.load_weights(saved_path + 'transformer_caption_model.h5')"
   ],
   "id": "ab640d433b95a42b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging of the proposed methods",
   "id": "efe0392784b62bca"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_grad_cam_explanation(image, label, pred, heatmap, mask, caption, alpha=128):\n",
    "\t\"\"\"\n",
    "\tPlots model input image, Grad-CAM heatmap, segmentation mask and the explanation generated\n",
    "\tArgs:\n",
    "\t\timage (numpy.ndarray): the input 3D image.\n",
    "\t\tlabel (int): the input image label.\n",
    "\t\tpred (int): model prediction for input image.\n",
    "\t\theatmap (numpy.ndarray): the Grad-CAM 3D heatmap.\n",
    "\t\tmask (numpy.ndarray): the computed 3D segmentation mask.\n",
    "\t\tcaption (string): the explanation generated caption.\n",
    "\t\talpha (int): transparency channel. Between 0 and 255.\n",
    "\tReturns:\n",
    "\t\tNone.\n",
    "\t\"\"\"\n",
    "\tif alpha >= 0 and alpha <= 255:\n",
    "\t\theatmap_mask = np.zeros((image.shape[0], image.shape[1], image.shape[2], 4), dtype='uint8')\n",
    "\t\theatmap_mask[mask == 1] = [255, 0, 0, alpha]\n",
    "\t\timage = image[:,:,int(image.shape[2] / 2)]\n",
    "\t\theatmap = heatmap[:,:,int(heatmap.shape[2] / 2)]\n",
    "\t\theatmap_mask = heatmap_mask[:,:,int(heatmap_mask.shape[2] / 2),:]\n",
    "\t\tfig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\t\tnorm_img = cv2.normalize(image, np.zeros((image.shape[1], image.shape[0])), 0, 1, cv2.NORM_MINMAX)\n",
    "\t\tim_shows = [\n",
    "\t\t\taxs[0].imshow(norm_img, cmap='gray', interpolation='bilinear', vmin = .0, vmax = 1.),\n",
    "\t\t\taxs[1].imshow(heatmap, cmap='jet', interpolation='bilinear', vmin = .0, vmax = 1.),\n",
    "\t\t\taxs[2].imshow(norm_img, cmap='gray', interpolation='bilinear', vmin = .0, vmax = 1.)\n",
    "\t\t]\n",
    "\t\taxs[2].imshow(heatmap_mask, interpolation='bilinear')\n",
    "\t\taxs[0].set_title('Label=' + ('NON-AD' if label == 0 else 'AD') + ' | Prediction=' + ('NON-AD' if pred == 0 else 'AD'), fontsize=16)\n",
    "\t\taxs[1].set_title('Grad-CAM Heatmap', fontsize=16)\n",
    "\t\taxs[2].set_title('Mask - Threshold ' + str(.8), fontsize=16)\n",
    "\t\tfor i, ax in enumerate(axs):\n",
    "\t\t\tax.axis('off')\n",
    "\t\t\tfig.colorbar(im_shows[i], ax=ax, ticks=np.linspace(0,1,6))\n",
    "            \n",
    "        # insert of caption generated\n",
    "        fig.text(0.5, 0.04, caption, ha='center', va='center')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "\t\tprint('\\n' + ''.join(['> ' for i in range(30)]))\n",
    "\t\tprint('\\nERROR: alpha channel \\033[95m '+alpha+'\\033[0m out of range [0,255].\\n')\n",
    "\t\tprint(''.join(['> ' for i in range(30)]) + '\\n')"
   ],
   "id": "18a2908249a121ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def get_results_and_plot(image_dict, predictor, generator,saved_path, plot=False):\n",
    "    '''\n",
    "    In this function we predict the class of the image after that we\n",
    "    keep the Grad-CAM and the explanation and return them\n",
    "    :param plot: if True we plot the Grad-CAM and explanation\n",
    "    :param saved_path: directory where the model weights are stored\n",
    "    :param image_dict: image dictionary\n",
    "    :param predictor: model for predict all value\n",
    "    :param generator: model for the generation of explanation\n",
    "    :param tokenizer: tokenizer object\n",
    "    :param max_length: maximum length of explanation\n",
    "    :return: \n",
    "    '''\n",
    "    \n",
    "    # Keep the image, the mask and the prediction\n",
    "    image, mask, pred, label, heatmap = get_gradcam(\n",
    "        example=image_dict,\n",
    "        model=predictor,\n",
    "        saved_path=saved_path,\n",
    "        threshold=.8,\n",
    "    )\n",
    "    \n",
    "    # Generate the description from the processed image\n",
    "    explanation = generator.predict(image)\n",
    "    \n",
    "    if plot:\n",
    "        plot_grad_cam_explanation(image, label, pred, heatmap, mask, explanation)\n",
    "    \n",
    "    return  image, label, pred, heatmap, mask, explanation"
   ],
   "id": "6dc33693af7c4208",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# get a random example from the entire dataset\n",
    "example = entire_df[random.randint(0, len(entire_df)-1)]\n",
    "get_results_and_plot(\n",
    "    image_dict=example,\n",
    "    predictor=densenet,\n",
    "    generator=caption_model,\n",
    "    saved_path=saved_path,\n",
    "    plot=True\n",
    ")"
   ],
   "id": "156869a8a6cbe018",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3a163c23e063c236",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
