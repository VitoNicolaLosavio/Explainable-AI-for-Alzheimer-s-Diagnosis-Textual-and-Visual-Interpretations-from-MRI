{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Alzheimer textual explanation, visual explanation and classification\n",
    "In this notebook there's all the procedure we do for the classification and for the explanation.\n",
    "\n",
    "For the realization of this project i start from the code of my colleague.\n",
    "\n",
    "In this notebook we suppose that you have already the dataset and the explanation, if else, \n",
    "you will run \"Creation of the dataset\" before this notebook."
   ],
   "id": "611567dbec5f4dc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:52.390853Z",
     "start_time": "2024-06-28T07:04:52.377290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, random, glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sys import platform\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical, plot_model \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense,\n",
    "    LSTM, Embedding,\n",
    "    Dropout, add,\n",
    "    MaxPool3D, Conv3D,\n",
    "    GlobalAveragePooling3D, BatchNormalization\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from alzheimer_disease.src.modules.postprocessing import get_gradcam, get_affected_areas\n",
    "from alzheimer_disease.src.helpers.utils import get_device\n",
    "from alzheimer_disease.src.modules.training import training_model\n",
    "from alzheimer_disease.src.helpers.config import get_config\n",
    "from alzheimer_disease.src.modules.preprocessing import get_transformations\n",
    "from alzheimer_disease.src.models.densenetmm import DenseNetMM"
   ],
   "id": "919f80c27494ade4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:52.401308Z",
     "start_time": "2024-06-28T07:04:52.395437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definition of all paths\n",
    "dataset = 'oasis_aug'\n",
    "\n",
    "_base_path = '/Volumes/Seagate Bas/Vito/CV'\n",
    "_config = get_config()\n",
    "saved_path = os.path.join(_base_path, _config.get('SAVED_FOLDER'))\n",
    "reports_path = os.path.join(_base_path, _config.get('REPORT_FOLDER'))\n",
    "logs_path = os.path.join(_base_path, _config.get('LOG_FOLDER'))\n",
    "_data_path = os.path.join(_base_path, _config.get('LOCAL_DATA'))\n",
    "data_path, meta_path, explanation_path = [\n",
    "    os.path.join(_data_path, dataset, 'data/'),\n",
    "    os.path.join(_data_path, dataset, 'meta/'),\n",
    "    os.path.join(_data_path, dataset, 'explainability/')\n",
    "]\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "if platform == 'win32':\n",
    "    saved_path = saved_path.replace('/', '\\\\')\n",
    "    reports_path = reports_path.replace('/', '\\\\')\n",
    "    logs_path = logs_path.replace('/', '\\\\')\n",
    "    data_path = data_path.replace('/', '\\\\')\n",
    "    meta_path = meta_path.replace('/', '\\\\')\n",
    "    explanation_path = explanation_path.replace('/', '\\\\')\n",
    "\n",
    "saved_path, reports_path, logs_path, data_path, meta_path, explanation_path, device"
   ],
   "id": "63f4224939e588e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Volumes/Seagate Bas/Vito/CV/saved/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/reports/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/logs/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/data/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/meta/',\n",
       " '/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/explainability/',\n",
       " 'cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:52.412024Z",
     "start_time": "2024-06-28T07:04:52.409144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SIZE = 128\n",
    "output_length = 1024\n",
    "epochs = 30\n",
    "\n",
    "CHANNELS = ['T2w']\n",
    "\n",
    "FEATURES = ['sex', 'age', 'bmi', 'education', 'cdr_memory', 'cdr_orientation', 'cdr_judgment', 'cdr_community', 'cdr_hobbies', 'cdr_personalcare', 'boston_naming_test', 'depression', 'sleeping_disorder', 'motor_disturbance']\n",
    "MULTICLASS = True"
   ],
   "id": "1abdcaaf50e4b278",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:52.437935Z",
     "start_time": "2024-06-28T07:04:52.423189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I started with the train test split of colleague and adapt to my task\n",
    "def train_test_splitting(\n",
    "        data_folder,\n",
    "        meta_folder,\n",
    "        explanation_folder,\n",
    "        channels,\n",
    "        features,\n",
    "        train_ratio=.8,\n",
    "        multiclass=False,\n",
    "        verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Splitting train/eval/test.\n",
    "    Args:\n",
    "        data_folder (str): path of the folder containing images.\n",
    "        meta_folder (str): path of the folder containing csv files.\n",
    "        explanation_folder (str): path of the folder containing csv files of the explanation.\n",
    "        channels (list): image channels to select (values `T1w`, `T2w` or both).\n",
    "        features (list): features set to select.\n",
    "        train_ratio (float): ratio of the training set, value between 0 and 1.\n",
    "        multiclass (bool): `False` for binary classification, `True` for ternary classification.\n",
    "        verbose (bool): whether or not print information.\n",
    "    Returns:\n",
    "        train_data (list): the training data ready to feed monai.data.Dataset\n",
    "        eval_data (list): the evaluation data ready to feed monai.data.Dataset\n",
    "        test_data (list): the testing data ready to feed monai.data.Dataset.\n",
    "        (see https://docs.monai.io/en/latest/data.html#monai.data.Dataset).\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.read_csv(os.path.join(meta_folder, 'data_num.csv'))\n",
    "    df1 = df[(df['weight'] != .0) & (df['height'] != .0)]\n",
    "    df['bmi'] = round(df1['weight'] / (df1['height'] * df1['height']), 0)\n",
    "    df['bmi'] = df['bmi'].fillna(.0)\n",
    "    sessions = [s.split('_')[0] for s in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, s))]\n",
    "    subjects = list(set(sessions))\n",
    "\n",
    "    # uploading of the dataset\n",
    "    explanation = pd.read_csv(explanation_folder + 'explaination.csv', sep=';')\n",
    "\n",
    "\n",
    "\n",
    "    # applying splitting on subjects to prevent data leakage\n",
    "    random.shuffle(subjects)\n",
    "    split_train = int(len(subjects) * train_ratio)\n",
    "    train_subjects, test_subjects = subjects[:split_train], subjects[split_train:]\n",
    "    split_eval = int(len(train_subjects) * .8)\n",
    "    eval_subjects = train_subjects[split_eval:]\n",
    "    train_subjects = train_subjects[:split_eval]\n",
    "\n",
    "    # applying multiclass label correction and splitting\n",
    "    if multiclass:\n",
    "        train_subjects, eval_subjects, test_subjects = [], [], []\n",
    "        df.loc[df['cdr'] == .0, 'final_dx'] = .0\n",
    "        df.loc[df['cdr'] == .5, 'final_dx'] = 1.\n",
    "        df.loc[(df['cdr'] != .0) & (df['cdr'] != .5), 'final_dx'] = 2.\n",
    "        m = np.min(np.unique(df['final_dx'].to_numpy(), return_counts=True)[1])\n",
    "        df = pd.concat([\n",
    "            df[df['final_dx'] == .0].sample(m),\n",
    "            df[df['final_dx'] == 1.].sample(m),\n",
    "            df[df['final_dx'] == 2.].sample(m)\n",
    "        ], ignore_index=True)\n",
    "        n_test = m - int(m * train_ratio)\n",
    "        n_eval = m - n_test - int(m * train_ratio * train_ratio)\n",
    "        for i in range(3):\n",
    "            sub = list(set(df[df['final_dx'] == float(i)]['subject_id'].to_numpy()))\n",
    "            random.shuffle(sub)\n",
    "            counter = 0\n",
    "            for j in range(len(sub)):\n",
    "                counter += len(df[df['subject_id'] == sub[j]])\n",
    "                if counter <= n_test:\n",
    "                    test_subjects.append(sub[j])\n",
    "                elif counter > n_test and counter <= (n_test + n_eval):\n",
    "                    eval_subjects.append(sub[j])\n",
    "                else:\n",
    "                    train_subjects.append(sub[j])\n",
    "\n",
    "    # loading sessions paths\n",
    "    X_train = df[df['subject_id'].isin(train_subjects)]\n",
    "    X_eval = df[df['subject_id'].isin(eval_subjects)]\n",
    "    X_test = df[df['subject_id'].isin(test_subjects)]\n",
    "    train_sessions = [os.path.join(data_folder, s) for s in X_train['session_id'].values]\n",
    "    eval_sessions = [os.path.join(data_folder, s) for s in X_eval['session_id'].values]\n",
    "    test_sessions = [os.path.join(data_folder, s) for s in X_test['session_id'].values]\n",
    "\n",
    "    # loading explanation of subjects\n",
    "    explanation_train = explanation[explanation['subject_id'].isin(X_train['subject_id'].values)]\n",
    "    explanation_eval = explanation[explanation['subject_id'].isin(X_eval['subject_id'].values)]\n",
    "    explanation_test = explanation[explanation['subject_id'].isin(X_test['subject_id'].values)]\n",
    "\n",
    "    # scaling numerical data in range [0,1]\n",
    "    X_train.loc[:, features] = scaler.fit_transform(X_train[features])\n",
    "    X_eval.loc[:, features] = scaler.fit_transform(X_eval[features])\n",
    "    X_test.loc[:, features] = scaler.fit_transform(X_test[features])\n",
    "\n",
    "    # arranging data in dictionaries\n",
    "    # I will also take the reference session of the explanation and the image\n",
    "    train_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_train[X_train['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_train[explanation_train['session_id'] == s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in train_sessions]\n",
    "    eval_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_eval[X_eval['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_eval[explanation_eval['session_id']==s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in eval_sessions]\n",
    "    test_data = [dict({\n",
    "        'image': sorted([os.path.join(s, i) for i in os.listdir(s) if any(c in i for c in channels)]),\n",
    "        'data': X_test[X_test['session_id'] == s.split('/')[-1]][features].values[0],\n",
    "        'label': df[df['session_id'] == s.split('/')[-1]]['final_dx'].values[0],\n",
    "        'explanation': explanation_test[explanation_test['session_id'] == s.split('/')[-1]]['explaination'].values[0],\n",
    "        'session_id': s.split('/')[-1]\n",
    "    }) for s in test_sessions]\n",
    "\n",
    "    # print data splitting information\n",
    "    if verbose:\n",
    "        print(''.join(['> ' for _ in range(40)]))\n",
    "        print(f'\\n{\"\":<20}{\"TRAINING\":<20}{\"EVALUATION\":<20}{\"TESTING\":<20}\\n')\n",
    "        print(''.join(['> ' for _ in range(40)]))\n",
    "        tsb1 = str(len(train_subjects)) + ' (' + str(round((len(train_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tsb2 = str(len(eval_subjects)) + ' (' + str(round((len(eval_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tsb3 = str(len(test_subjects)) + ' (' + str(round((len(test_subjects) * 100 / len(df['subject_id'].unique())), 0)) + ' %)'\n",
    "        tss1 = str(len(train_sessions)) + ' (' + str(round((len(train_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        tss2 = str(len(eval_sessions)) + ' (' + str(round((len(eval_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        tss3 = str(len(test_sessions)) + ' (' + str(round((len(test_sessions) * 100 / len(df)), 2)) + ' %)'\n",
    "        print(f'\\n{\"subjects\":<20}{tsb1:<20}{tsb2:<20}{tsb3:<20}\\n')\n",
    "        print(f'{\"sessions\":<20}{tss1:<20}{tss2:<20}{tss3:<20}\\n')\n",
    "\n",
    "    return train_data, eval_data, test_data"
   ],
   "id": "7c21fb3c080ba3ce",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:52.636869Z",
     "start_time": "2024-06-28T07:04:52.439301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "densenet = DenseNetMM(\n",
    "    in_channels = len(CHANNELS),\n",
    "    in_size = SIZE,\n",
    "    in_features_size= len(FEATURES),\n",
    "    out_channels = 3 if MULTICLASS else 2,\n",
    "    append_features = True\n",
    ")"
   ],
   "id": "21759584931463d9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:54.448865Z",
     "start_time": "2024-06-28T07:04:52.637592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform, eval_transform = get_transformations(size=SIZE)\n",
    "\n",
    "train, val, test = train_test_splitting(\n",
    "    data_folder=data_path,\n",
    "    meta_folder=meta_path,\n",
    "    explanation_folder=explanation_path,\n",
    "    channels=CHANNELS,\n",
    "    features=FEATURES,\n",
    "    multiclass=MULTICLASS,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "6b704a8642ecf907",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
      "\n",
      "                    TRAINING            EVALUATION          TESTING             \n",
      "\n",
      "> > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
      "\n",
      "subjects            381 (64.0 %)        94 (16.0 %)         118 (20.0 %)        \n",
      "\n",
      "sessions            440 (64.33 %)       107 (15.64 %)       137 (20.03 %)       \n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:54.452718Z",
     "start_time": "2024-06-28T07:04:54.450229Z"
    }
   },
   "cell_type": "code",
   "source": "train[0]",
   "id": "a143df277ef4f5dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': ['/Volumes/Seagate Bas/Vito/CV/data/oasis_aug/data/OAS31302_MR_d0056/sub-OAS31302_sess-d0056_T2w.nii.gz'],\n",
       " 'data': array([1.        , 0.47916667, 0.63043478, 0.66666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.5       ]),\n",
       " 'label': 0.0,\n",
       " 'explanation': \"**Summary of Heatmap Analysis**\\n\\nThe heatmap analysis reveals that the classification model focused on specific regions in the brain, which are not areas typically affected by Alzheimer's Disease. The following regions were highlighted in the heatmap:\\n\\n1. **Frontal-to-Occipital (GapMap) left**: This region accounted for 19.9% of the heatmap and 17.81% of the affected region. The GapMap region is responsible for processing visual information and integrating it with other sensory inputs. The model's focus on this region may indicate that the patient's visual processing abilities were affected, potentially contributing to the diagnosis of Alzheimer's Disease. Clinically, this could suggest that the patient's visual acuity, depth perception, or color vision may be impaired, warranting further investigation.\\n2. **Area hOc1 (V1, 17, CalcS) left**: This region accounted for 13.24% of the heatmap and 43.39% of the affected region. Area hOc1 is involved in processing visual information from the primary visual cortex. The model's focus on this region may suggest that the patient's visual processing abilities were compromised, potentially impacting their ability to recognize objects, faces, or navigate their environment. Clinically, this could indicate that the patient's visual processing abilities are impaired, and they may require assistance with daily activities.\\n3. **Temporal-to-Parietal (GapMap) left**: This region accounted for 12.87% of the heatmap and 7.68% of the affected region. The Temporal-to-Parietal region is involved in processing auditory and visual information, as well as integrating it with other sensory inputs. The model's focus on this region may indicate that the patient's auditory processing abilities were affected, potentially contributing to the diagnosis of Alzheimer's Disease. Clinically, this could suggest that the patient's hearing loss or difficulty understanding speech may be a symptom of the disease.\\n4. **Area hOc4v (LingG) left**: This region accounted for 8.06% of the heatmap and 68.77% of the affected region. Area hOc4v is involved in processing linguistic information and is responsible for language processing. The model's focus on this region may suggest that the patient's language processing abilities were compromised, potentially impacting their ability to communicate effectively. Clinically, this could indicate that the patient's language skills are impaired, and they may require assistance with communication.\\n5. **Area hOc3v (LingG) left**: This region accounted for 6.54% of the heatmap and 51.49% of the affected region. Area hOc3v is also involved in processing linguistic information and is responsible for language processing. The model's focus on this region may indicate that the patient's language processing abilities were affected, potentially contributing to the diagnosis of Alzheimer's Disease. Clinically, this could suggest that the patient's language skills are impaired, and they may require assistance with communication.\\n\\n**Conclusion**\\n\\nThe heatmap analysis provides valuable insights into the regions that the classification model focused on to make its classification decision. The highlighted regions are not areas typically affected by Alzheimer's Disease, but rather areas that were the most relevant for the model to reach its decision. The clinical implications of the model's focus on these regions suggest that the patient's visual processing abilities, auditory processing abilities, and language processing abilities may be impaired. These findings could enhance clinical decision-making and potentially reveal new aspects of Alzheimer's Disease pathology and diagnosis.\",\n",
       " 'session_id': 'OAS31302_MR_d0056'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:04:55.704967Z",
     "start_time": "2024-06-28T07:04:54.453276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if glob.glob(saved_path+ 'DenseNetMM_best.pth'):\n",
    "\tprint('Loading DenseNetMM_best.pth')\n",
    "\tdensenet.load_state_dict(torch.load(saved_path + 'DenseNetMM_best.pth'))\n",
    "else:\n",
    "\tprint('Train of the model')\n",
    "\ttrain_metrics = training_model(\n",
    "\t\tmodel = densenet,\n",
    "\t\tdata = [train, val],\n",
    "\t\ttransforms = [train_transform, eval_transform],\n",
    "\t\tepochs = epochs,\n",
    "\t\tdevice = get_device(),\n",
    "\t\tpaths = [saved_path, reports_path, logs_path],\n",
    "\t\tnum_workers=0,\n",
    "\t\tverbose=True\n",
    "\t)"
   ],
   "id": "75dba86d23bdb8d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DenseNetMM_best.pth\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Image Captioning",
   "id": "151e3073d8cfb812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:51:25.791419Z",
     "start_time": "2024-06-28T08:51:25.786796Z"
    }
   },
   "cell_type": "code",
   "source": "name_fextractor = 'DenseNetMMFeatureExtractor'",
   "id": "36632317f8234359",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:51:26.324289Z",
     "start_time": "2024-06-28T08:51:26.205171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from monai.data import CacheDataset\n",
    "\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    re1 = re.compile(r'  +')\n",
    "    x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '', \"\\n\").replace('\\\"', '\"').replace('', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\'', ' \\ ')\n",
    "    return re1.sub(' ', html.unescape(x1))\n",
    "\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def replace_numbers(text):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def remove_whitespaces(text):\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "    \"\"\"\n",
    "    :param words:\n",
    "    :type words:\n",
    "    :param stop_words: from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "    or\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    :type stop_words:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def addsequences(text):\n",
    "  return '' .join('startseq ' + \" \".join([word for word in text.split() if len(word)>1]) + ' endseq')\n",
    "\n",
    "def text2words(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def normalize_text( text):\n",
    "    text = remove_special_chars(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lowercase(text)\n",
    "    text = replace_numbers(text)\n",
    "    text = addsequences(text)\n",
    "    return text\n",
    "  \n",
    "def normalize_corpus(corpus):\n",
    "    return [normalize_text(t) for t in corpus]\n",
    "\n",
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# concat for get all df\n",
    "entire_df = train + val + test\n",
    "\n",
    "all_text = [explaination['explanation'] for explaination in entire_df]\n",
    "\n",
    "# tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(all_text))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: {}'.format(vocab_size))"
   ],
   "id": "abeaaea064344a10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1154\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:53:19.681520Z",
     "start_time": "2024-06-28T08:51:27.033104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_extractor = DenseNetMM(\n",
    "    in_channels = len(CHANNELS),\n",
    "    in_size = SIZE,\n",
    "    in_features_size= len(FEATURES),\n",
    "    out_channels = 3 if MULTICLASS else 2,\n",
    "    append_features = False,\n",
    "    name=name_fextractor\n",
    ")\n",
    "\n",
    "if glob.glob(saved_path+ f'{name_fextractor}.pth'):\n",
    "\tprint('Loading DenseNetMM_best.pth for feature extraction')\n",
    "\tfeature_extractor.load_state_dict(torch.load(saved_path + 'DenseNetMM_best.pth'))\n",
    "else:\n",
    "\tprint('Train of the model for feature extraction')\n",
    "\ttrain_metrics = training_model(\n",
    "\t\tmodel = feature_extractor,\n",
    "\t\tdata = [train, val],\n",
    "\t\ttransforms = [train_transform, eval_transform],\n",
    "\t\tepochs = epochs,\n",
    "\t\tdevice = get_device(),\n",
    "\t\tpaths = [saved_path, reports_path, logs_path],\n",
    "\t\tnum_workers=0,\n",
    "\t\tverbose=True\n",
    "\t)\n",
    "\n",
    "\n",
    "# restructure the model    \n",
    "feature_extractor = Model(inputs=feature_extractor.inputs, outputs=feature_extractor.layers[-2].output)\n",
    "# summarize\n",
    "print(feature_extractor.summary())"
   ],
   "id": "76a1da181f4fc94c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train of the model for feature extraction\n",
      "> > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
      "epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m \t\u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain of the model for feature extraction\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m \ttrain_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mtransforms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_transform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_transform\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mget_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43msaved_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreports_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs_path\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     24\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# restructure the model    \u001B[39;00m\n\u001B[1;32m     28\u001B[0m feature_extractor \u001B[38;5;241m=\u001B[39m Model(inputs\u001B[38;5;241m=\u001B[39mfeature_extractor\u001B[38;5;241m.\u001B[39minputs, outputs\u001B[38;5;241m=\u001B[39mfeature_extractor\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39moutput)\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/alzheimer_disease/src/modules/training.py:291\u001B[0m, in \u001B[0;36mtraining_model\u001B[0;34m(model, data, transforms, epochs, device, paths, batch_size, val_interval, early_stopping, num_workers, ministep, write_to_file, verbose)\u001B[0m\n\u001B[1;32m    289\u001B[0m \toutputs \u001B[38;5;241m=\u001B[39m model([inputs_img, inputs_data])\n\u001B[1;32m    290\u001B[0m \tloss \u001B[38;5;241m=\u001B[39m loss_function(outputs, labels)\n\u001B[0;32m--> 291\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[1;32m    293\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/_tensor.py:516\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \n\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m        used to compute the attr::tensors.\u001B[39;00m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhandle_torch_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mTensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    527\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/overrides.py:1636\u001B[0m, in \u001B[0;36mhandle_torch_function\u001B[0;34m(public_api, relevant_args, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1630\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1631\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be an error in future, please define it as a classmethod.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1632\u001B[0m                   \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[1;32m   1634\u001B[0m \u001B[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001B[39;00m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;66;03m# implementations can do equality/identity comparisons.\u001B[39;00m\n\u001B[0;32m-> 1636\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch_func_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpublic_api\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m   1639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/monai/data/meta_tensor.py:282\u001B[0m, in \u001B[0;36mMetaTensor.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 282\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__torch_function__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# if \"out\" in kwargs:\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;66;03m#     return ret\u001B[39;00m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _not_requiring_metadata(ret):\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/_tensor.py:1443\u001B[0m, in \u001B[0;36mTensor.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m   1440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m   1442\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[0;32m-> 1443\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1444\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[1;32m   1445\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Computer_Vision_Code/CV_Project/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:46:57.808270Z",
     "start_time": "2024-06-28T08:46:57.796311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in feature_extractor.named_children():\n",
    "    print(i)"
   ],
   "id": "a73cbe58bf77e466",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features_img', Sequential(\n",
      "  (conv0): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "  (norm0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace=True)\n",
      "  (pool0): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(96, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (layers): Sequential(\n",
      "        (norm1): BatchNorm3d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "))\n",
      "('output_layers', Sequential(\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (pool): AdaptiveAvgPool3d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "))\n",
      "('features_data', Sequential(\n",
      "  (0): Linear(in_features=14, out_features=64, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Dropout(p=0.3, inplace=False)\n",
      "  (7): Flatten(start_dim=1, end_dim=-1)\n",
      "))\n",
      "('final_classification_img_only', Sequential(\n",
      "  (out): Linear(in_features=1024, out_features=3, bias=True)\n",
      "))\n",
      "('final_classification_mm', Sequential(\n",
      "  (lin): Linear(in_features=1280, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=3, bias=True)\n",
      "))\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# extract features from image\n",
    "features = {}\n",
    "entire_df = CacheDataset(entire_df, transform=eval_transform, cache_rate=1.0, num_workers=None, progress=False)\n",
    "entire_df = DataLoader(entire_df, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "for img_name in tqdm(entire_df):\n",
    "    val_inputs_img, val_inputs_data, session_id  = (\n",
    "        img_name['image'].to(device),\n",
    "        img_name['data'].to(device),\n",
    "        img_name['session_id'].to(device)\n",
    "    )\n",
    "    \n",
    "    # extract features\n",
    "    feature = feature_extractor.predict([val_inputs_img, val_inputs_data])\n",
    "    # store feature\n",
    "    features[session_id] = feature\n",
    "features"
   ],
   "id": "2c3f2343da09757e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pickle.dump(features, open(os.path.join(saved_path, 'clef_features_vgg.pkl'), 'wb'))",
   "id": "6bd47997a581c0fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if glob.glob(saved_path + 'clef_features_vgg.pkl'):\n",
    "    with open(os.path.join(saved_path, 'clef_features_vgg.pkl'), 'rb') as f:\n",
    "        features = pickle.load(f)"
   ],
   "id": "828b9d754e572382",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# encoder model\n",
    "# image feature layers\n",
    "inputs1 = Input((128, 128, 50, 1))\n",
    "\n",
    "encoding = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs1)\n",
    "encoding = MaxPool3D(pool_size=2)(encoding)\n",
    "encoding = BatchNormalization()(encoding)\n",
    "\n",
    "encoding = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(encoding)\n",
    "encoding = MaxPool3D(pool_size=2)(encoding)\n",
    "encoding = BatchNormalization()(encoding)\n",
    "\n",
    "encoding = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(encoding)\n",
    "encoding = MaxPool3D(pool_size=2)(encoding)\n",
    "encoding = BatchNormalization()(encoding)\n",
    "\n",
    "encoding = Conv3D(filters=256, kernel_size=3, activation=\"relu\")(encoding)\n",
    "encoding = MaxPool3D(pool_size=2)(encoding)\n",
    "encoding = BatchNormalization()(encoding)\n",
    "\n",
    "encoding = GlobalAveragePooling3D()(encoding)\n",
    "encoding = Dense(units=512, activation=\"relu\")(encoding)\n",
    "encoding = Dropout(0.3)(encoding)\n",
    "\n",
    "# sequence feature layers\n",
    "inputs2 = Input(shape=(output_length,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "# decoder model\n",
    "decoder = add([encoding, se3])\n",
    "decoder = Dense(256, activation='relu')(decoder)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "generation_model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "generation_model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"accuracy\"])\n",
    "\n",
    "# plot the model\n",
    "plot_model(generation_model, show_shapes=True)"
   ],
   "id": "b9b7e473db449f92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create data generator to get data in batch (avoids session crash)\n",
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            feature_key = key.split('.')[0]\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    # store the sequences\n",
    "                    #print([key])\n",
    "                    X1.append(features[feature_key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield [X1, X2], y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0"
   ],
   "id": "ff6da244206dca5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train the model\n",
    "batch_size = 32\n",
    "steps = len(train) // batch_size\n",
    "\n",
    "train_generator = data_generator(train, mapping, features, tokenizer, output_length, vocab_size, batch_size)\n",
    "val_generator = data_generator(val, mapping, features, tokenizer, output_length, vocab_size, batch_size)\n",
    "# fit for 10 epoch\n",
    "generation_model.fit(train_generator, epochs=epochs,validation_data=val_generator, steps_per_epoch=steps, verbose=1)\n",
    "generation_model.save(saved_path+'/model_generation.h5')"
   ],
   "id": "fe142bc1fe6e03b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "      \n",
    "    return in_text"
   ],
   "id": "818a35cc7dc91324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# validate with test data\n",
    "actual, predicted = list(), list()\n",
    "all_captions = []\n",
    "\n",
    "for key in tqdm(test):\n",
    "    # get actual caption\n",
    "    feature_key = key.split('.')[0]\n",
    "    captions = mapping[key]\n",
    "    # predict the caption for image\n",
    "    y_pred = predict_caption(generation_model, features[feature_key], tokenizer, output_length)\n",
    "    all_captions.append(y_pred)\n",
    "    # split into words\n",
    "    actual_captions = [caption.split() for caption in captions]\n",
    "    y_pred = y_pred.split()\n",
    "    # append to the list\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "    \n",
    "# calcuate BLEU score\n",
    "print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "print(all_captions[0]) "
   ],
   "id": "bc745e0cb956b4b9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
